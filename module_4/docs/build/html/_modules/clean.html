<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>clean &#8212; GradCafe Analytics 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=f2a433a1"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for clean</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">urllib.error</span>


<div class="viewcode-block" id="DataCleaner">
<a class="viewcode-back" href="../api.html#clean.DataCleaner">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DataCleaner</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    clean.py</span>
<span class="sd">    --------</span>
<span class="sd">    This script takes the raw scraper output (applicant_data.json) and &quot;cleans&quot; it by</span>
<span class="sd">    standardizing the program + university names using the professor provided local LLM tool.</span>

<span class="sd">    The professor tool produces the following output keys (and the assignment expects them):</span>
<span class="sd">      - llm-generated-program</span>
<span class="sd">      - llm-generated-university</span>

<span class="sd">    Default behavior / priority order:</span>
<span class="sd">      1) Preferred: call the local Flask API (llm_hosting/app.py --serve)</span>
<span class="sd">         Endpoint: http://localhost:8000/standardize</span>
<span class="sd">         Benefit: batching is faster and reduces overhead.</span>
<span class="sd">      2) Fallback: if the server is not running (or becomes unavailable mid-run),</span>
<span class="sd">         import llm_hosting.app and call _call_llm() directly.</span>

<span class="sd">    Notes on performance:</span>
<span class="sd">      - We batch requests when using the API.</span>
<span class="sd">      - We cache results keyed by the raw &quot;program&quot; string to avoid repeated LLM calls.</span>
<span class="sd">        (In GradCafe data, duplicates are extremely common.)</span>
<span class="sd">      - Output is saved atomically so long runs can be resumed safely.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;applicant_data.json&quot;</span><span class="p">,</span>
        <span class="n">output_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;llm_extend_applicant_data.json&quot;</span><span class="p">,</span>
        <span class="n">api_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:8000/standardize&quot;</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">timeout_seconds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Input: output from scrape.py</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_file</span> <span class="o">=</span> <span class="n">input_file</span>

        <span class="c1"># Output: same rows + the two LLM-generated fields appended</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_file</span> <span class="o">=</span> <span class="n">output_file</span>

        <span class="c1"># Local LLM server endpoint (Option A in your workflow)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_url</span> <span class="o">=</span> <span class="n">api_url</span>

        <span class="c1"># Batch size for API mode (50 is a reasonable tradeoff for speed vs stability)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="c1"># Network timeout for the local API call</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timeout_seconds</span> <span class="o">=</span> <span class="n">timeout_seconds</span>

        <span class="c1"># Cache standardizations keyed by raw &quot;program&quot; field.</span>
        <span class="c1"># This is the biggest speed-up for large runs (30k rows).</span>
        <span class="c1">#</span>
        <span class="c1"># If you ever wanted to broaden the cache, you could include university too,</span>
        <span class="c1"># but program alone usually captures most duplicates.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_input</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load applicant_data.json and return the parsed JSON data.</span>

<span class="sd">        Expected format:</span>
<span class="sd">          - a JSON list of dict rows produced by scrape.py</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_file</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_file</span><span class="si">}</span><span class="s2"> not found.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_atomic_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save output safely.</span>

<span class="sd">        We write to a temp file first and then replace the real output file.</span>
<span class="sd">        This prevents partial/corrupt JSON if the program is interrupted mid-write.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tmp_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_file</span> <span class="o">+</span> <span class="s2">&quot;.tmp&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_file</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_post_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        POST JSON to the local standardizer API using urllib (lecture topics).</span>

<span class="sd">        The server expects:</span>
<span class="sd">          {&quot;rows&quot;: [ { &quot;program&quot;: &quot;...&quot;, ... }, ... ]}</span>

<span class="sd">        And returns a dict with:</span>
<span class="sd">          {&quot;rows&quot;: [ { ..., &quot;llm-generated-program&quot;: &quot;...&quot;, &quot;llm-generated-university&quot;: &quot;...&quot; }, ... ]}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">body</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">api_url</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">body</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Content-Type&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">},</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;POST&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout_seconds</span><span class="p">)</span> <span class="k">as</span> <span class="n">resp</span><span class="p">:</span>
            <span class="n">raw</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_can_use_api</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Quick health check: try a single tiny request.</span>

<span class="sd">        If it works, we run in fast &quot;API (batched)&quot; mode.</span>
<span class="sd">        If it fails, we fall back to direct import mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_json</span><span class="p">({</span><span class="s2">&quot;rows&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;program&quot;</span><span class="p">:</span> <span class="s2">&quot;Information Studies, McGill University&quot;</span><span class="p">}]})</span>
            <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rows&quot;</span><span class="p">),</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_direct_standardize_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fallback mode (no server):</span>
<span class="sd">        Import llm_hosting.app and call _call_llm(program_text) directly.</span>

<span class="sd">        The professor function returns:</span>
<span class="sd">          { &quot;standardized_program&quot;: &quot;...&quot;, &quot;standardized_university&quot;: &quot;...&quot; }</span>

<span class="sd">        We then map those outputs into the assignment-required keys:</span>
<span class="sd">          - llm-generated-program</span>
<span class="sd">          - llm-generated-university</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Expect llm_hosting/ to be a subfolder in module_2.</span>
            <span class="c1"># It must be importable (llm_hosting/__init__.py exists).</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">llm_hosting</span><span class="w"> </span><span class="kn">import</span> <span class="n">app</span> <span class="k">as</span> <span class="n">llm_app</span>  <span class="c1"># type: ignore</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import llm_hosting.app. &quot;</span>
                <span class="s2">&quot;Make sure the llm_hosting folder is present and importable.&quot;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># The professor LLM tool takes the raw program text and returns standardized fields.</span>
        <span class="n">program_text</span> <span class="o">=</span> <span class="p">(</span><span class="n">row</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">llm_app</span><span class="o">.</span><span class="n">_call_llm</span><span class="p">(</span><span class="n">program_text</span><span class="p">)</span>  <span class="c1"># returns dict with standardized_program/university</span>

        <span class="c1"># Store the outputs using the assignment-required key names.</span>
        <span class="n">row</span><span class="p">[</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;standardized_program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
        <span class="n">row</span><span class="p">[</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;standardized_university&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">row</span>

<div class="viewcode-block" id="DataCleaner.clean_data">
<a class="viewcode-back" href="../api.html#clean.DataCleaner.clean_data">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">clean_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Main cleaning routine:</span>
<span class="sd">          - Load scraped rows</span>
<span class="sd">          - Standardize each row via LLM (batched API if possible)</span>
<span class="sd">          - Cache repeats</span>
<span class="sd">          - Save output periodically and at the end</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_input</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Scraper output must be a list of rows.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: applicant_data.json must be a JSON list of rows.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No rows found in input.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_atomic_save</span><span class="p">([])</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Decide whether we can use the faster local API mode.</span>
        <span class="n">use_api</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_can_use_api</span><span class="p">()</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;API (batched)&quot;</span> <span class="k">if</span> <span class="n">use_api</span> <span class="k">else</span> <span class="s2">&quot;Direct import&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting LLM cleaning on </span><span class="si">{</span><span class="n">total</span><span class="si">}</span><span class="s2"> rows using: </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">cleaned</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">cache_hits</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Process in batches so:</span>
        <span class="c1">#  - API mode can send many rows at once</span>
        <span class="c1">#  - We can periodically checkpoint progress</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">total</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

            <span class="c1"># Cache first:</span>
            <span class="c1"># Many program strings repeat; if we’ve already standardized this exact program</span>
            <span class="c1"># text, we can copy the cached LLM outputs without calling the model again.</span>
            <span class="n">to_send</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">send_map</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># indices of rows in batch that were NOT cache hits</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="n">program_key</span> <span class="o">=</span> <span class="p">((</span><span class="n">row</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

                <span class="c1"># Cache hit: copy LLM-generated fields into this row immediately.</span>
                <span class="k">if</span> <span class="n">program_key</span> <span class="ow">and</span> <span class="n">program_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
                    <span class="n">row</span><span class="p">[</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">program_key</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">)</span>
                    <span class="n">row</span><span class="p">[</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">program_key</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">)</span>
                    <span class="n">cache_hits</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Cache miss: we need to standardize this row via LLM.</span>
                    <span class="n">to_send</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
                    <span class="n">send_map</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

            <span class="c1"># Standardize only the non-cached rows.</span>
            <span class="k">if</span> <span class="n">to_send</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">use_api</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="c1"># Batched API call: fastest path when the server is running.</span>
                        <span class="n">resp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_json</span><span class="p">({</span><span class="s2">&quot;rows&quot;</span><span class="p">:</span> <span class="n">to_send</span><span class="p">})</span>
                        <span class="n">out_rows</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rows&quot;</span><span class="p">,</span> <span class="p">[])</span>

                        <span class="c1"># Basic validation: response should contain one output row per input row.</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_rows</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_rows</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_send</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unexpected API response shape.&quot;</span><span class="p">)</span>

                        <span class="c1"># Update cache with freshly standardized results.</span>
                        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">out_rows</span><span class="p">:</span>
                            <span class="n">program_key</span> <span class="o">=</span> <span class="p">((</span><span class="n">r</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">program_key</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">program_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                                    <span class="s2">&quot;llm-generated-program&quot;</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                                    <span class="s2">&quot;llm-generated-university&quot;</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                                <span class="p">}</span>

                        <span class="c1"># Merge standardized rows back into the original batch positions.</span>
                        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">original_batch_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">send_map</span><span class="p">):</span>
                            <span class="n">batch</span><span class="p">[</span><span class="n">original_batch_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_rows</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="c1"># If the API fails mid-run (server crash, timeout, etc.),</span>
                        <span class="c1"># switch to direct import mode for the remainder of the job.</span>
                        <span class="n">use_api</span> <span class="o">=</span> <span class="kc">False</span>

                        <span class="k">for</span> <span class="n">original_batch_index</span> <span class="ow">in</span> <span class="n">send_map</span><span class="p">:</span>
                            <span class="n">row</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">original_batch_index</span><span class="p">]</span>
                            <span class="n">row</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_direct_standardize_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

                            <span class="n">program_key</span> <span class="o">=</span> <span class="p">((</span><span class="n">row</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">program_key</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">program_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                                    <span class="s2">&quot;llm-generated-program&quot;</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                                    <span class="s2">&quot;llm-generated-university&quot;</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                                <span class="p">}</span>

                            <span class="n">batch</span><span class="p">[</span><span class="n">original_batch_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Direct import mode: standardize one row at a time.</span>
                    <span class="c1"># Slower than API batching, but works even without the server.</span>
                    <span class="k">for</span> <span class="n">original_batch_index</span> <span class="ow">in</span> <span class="n">send_map</span><span class="p">:</span>
                        <span class="n">row</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">original_batch_index</span><span class="p">]</span>
                        <span class="n">row</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_direct_standardize_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

                        <span class="c1"># Cache results so duplicates are fast going forward.</span>
                        <span class="n">program_key</span> <span class="o">=</span> <span class="p">((</span><span class="n">row</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">program_key</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">program_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                                <span class="s2">&quot;llm-generated-program&quot;</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-program&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                                <span class="s2">&quot;llm-generated-university&quot;</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm-generated-university&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="p">}</span>

                        <span class="n">batch</span><span class="p">[</span><span class="n">original_batch_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span>

            <span class="c1"># Add the processed batch to our final list and advance the cursor.</span>
            <span class="n">cleaned</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># Progress indicator (single updating line in terminal).</span>
            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
            <span class="n">pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Cleaning: </span><span class="si">{</span><span class="n">pct</span><span class="si">:</span><span class="s2">6.2f</span><span class="si">}</span><span class="s2">% | </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total</span><span class="si">}</span><span class="s2"> | Cache hits: </span><span class="si">{</span><span class="n">cache_hits</span><span class="si">}</span><span class="s2"> | Elapsed: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s&quot;</span>
            <span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

            <span class="c1"># Periodic checkpoint so you don’t lose hours of work if interrupted.</span>
            <span class="c1"># Every 1000 rows is a good balance between overhead and safety.</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_atomic_save</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>

        <span class="c1"># Final save to ensure output is complete and up to date.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_atomic_save</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Saved cleaned output to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cleaned</span></div>
</div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Default run: read applicant_data.json and write llm_extend_applicant_data.json</span>
    <span class="c1"># If you want to customize behavior, adjust DataCleaner() parameters above.</span>
    <span class="n">cleaner</span> <span class="o">=</span> <span class="n">DataCleaner</span><span class="p">()</span>
    <span class="n">cleaner</span><span class="o">.</span><span class="n">clean_data</span><span class="p">()</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">GradCafe Analytics</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2026, Eugene Buyanovsky.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>